{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dd639f-2b7a-4b05-bd39-cfd9e1ebf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd03bfc-78fd-47da-9cca-2cd4caea932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d892a9ef-a10b-4a8b-a042-df5073ee8cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\Hisha\\AppData\\Local\\Temp\\tmpqz4wysih\\config.json as plain json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Hisha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.3.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\Hisha\\AppData\\Local\\Temp\\tmpzavlkvrp\\config.json as plain json\n"
     ]
    }
   ],
   "source": [
    "bert = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
    "bilstm = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6438b5a-eef9-49ac-996d-8a513b3a653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read the datasets\n",
    "dict_list = []\n",
    "# Loop over the filenames and load each JSON file into a dictionary\n",
    "for i in range(1, 7):\n",
    "    filename = f\"datasets\\data{i}.json\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        dict_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cde186a-c31f-4b3f-a0eb-8585285c10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lists(list1, list2, dictionary):\n",
    "    \"\"\"\n",
    "    Compare two lists of lists and return error rate, ratio of correctly classified items, and a list of incorrect sentences.\n",
    "\n",
    "    Args:\n",
    "    - list1 (list): The first list of lists to compare. Original tags/ expected\n",
    "    - list2 (list): The second list of lists to compare. Predicted Tags.\n",
    "    - dictionary (dict): A dictionary containing information about each sentence being compared. The dictionary returned by running the models.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the error rate, ratio of correctly classified items, and a list of incorrect sentences.\n",
    "    \"\"\"\n",
    "    total_items = 0\n",
    "    correct_items = 0\n",
    "    incorrect_items = 0\n",
    "    incorrect_indices = []\n",
    "\n",
    "    # Loop over each element in both lists of lists and compare them\n",
    "    for i in range(len(list1)):\n",
    "        if not list1[i] or not list2[i]:\n",
    "            continue  # Skip empty lists\n",
    "        total_items += 1\n",
    "        if list1[i] == list2[i]:\n",
    "            correct_items += 1\n",
    "        else:\n",
    "            incorrect_items += 1\n",
    "            incorrect_indices.append((i))\n",
    "\n",
    "    # Calculate the error rate, ratio of incorrectly classified items, and ratio of correctly classified items\n",
    "    error_rate = incorrect_items / total_items\n",
    "    ratio_correct = correct_items / total_items\n",
    "\n",
    "    # Get the sentences corresponding to the incorrect indices\n",
    "    incorrect_sentences = []\n",
    "    for i in incorrect_indices:\n",
    "        if len(dictionary[i]['verbs']) == 2:\n",
    "            sentence = \" \".join(dictionary[i]['words'])\n",
    "            res_tags = \" \".join(dictionary[i]['verbs'][1]['tags'])\n",
    "            tags = list1[i]\n",
    "            incorrect_sentences.append((i, sentence, res_tags, tags))\n",
    "        elif len(dictionary[i]['verbs']) == 1:\n",
    "            sentence = \" \".join(dictionary[i]['words'])\n",
    "            res_tags = \" \".join(dictionary[i]['verbs'][0]['tags'])\n",
    "            tags = list1[i]\n",
    "            incorrect_sentences.append((i, sentence, res_tags, tags))\n",
    "        else:\n",
    "            sentence = \" \".join(dictionary[i]['words'])\n",
    "            res_tags = \"\"\n",
    "            tags = list1[i]\n",
    "            incorrect_sentences.append({'index': i, 'sentence': sentence, 'predicted': res_tags, 'expected': tags})\n",
    "\n",
    "    return error_rate, ratio_correct, incorrect_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62b3cd0-e678-4a22-84f3-7bc2537f76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_eval(dict_list, model, save_output = False, model_name = None):\n",
    "    \"\"\"\n",
    "    Evaluates a list of dictionaries containing sentences and their corresponding tags\n",
    "    using a spaCy model, and returns a list of DataFrames containing the incorrectly\n",
    "    classified sentences for each dictionary.\n",
    "\n",
    "    Args:\n",
    "    - dict_list (List[Dict[str, Union[str, List[str]]]]): A list of dictionaries containing\n",
    "      sentences and their corresponding tags.\n",
    "    - model (Language): A spaCy model object.\n",
    "    - save_output: Boolean to save the output or not\n",
    "    - model_name: string denoting the name fo the model to be used in the file path name\n",
    "\n",
    "    Returns:\n",
    "    - dfs (List[pandas.DataFrame]): A list of DataFrames containing the incorrectly classified\n",
    "      sentences for each dictionary.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i, dic in enumerate(dict_list):\n",
    "        res = model.predict_batch_json(dic)\n",
    "        if save_output:\n",
    "            # Write the data to a JSON file\n",
    "            filename = f\"outputs\\output_{model_name}{i+1}.json\"\n",
    "            with open(filename, \"w\") as outfile:\n",
    "                json.dump(res, outfile)\n",
    "        tags = [x['tags'] for x in dic]\n",
    "        res_tags = []\n",
    "        for x in res:\n",
    "            if len(x['verbs']) == 2:\n",
    "                res_tags.append(x['verbs'][1]['tags'])\n",
    "            elif len(x['verbs']) == 1:\n",
    "                res_tags.append(x['verbs'][0]['tags'])\n",
    "            else:\n",
    "                res_tags.append([])\n",
    "        \n",
    "        error_rate, ratio_correct, incorrect_sentences = compare_lists(tags, res_tags, res)\n",
    "        dfs.append(pd.DataFrame(incorrect_sentences, columns=['index', 'sentence', 'predicted', 'expected']))\n",
    "        print(f\"Test {i+1}\")\n",
    "        print(\"Error rate:\", error_rate)\n",
    "        print(\"Ratio of correctly classified items:\", ratio_correct)\n",
    "        print(\"\\n\")\n",
    "    return dfs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c17caa11-71ed-40e8-9ad9-53047c494b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### BERT ###################\n",
      "Test 1\n",
      "Error rate: 0.0\n",
      "Ratio of correctly classified items: 1.0\n",
      "\n",
      "\n",
      "Test 2\n",
      "Error rate: 0.0\n",
      "Ratio of correctly classified items: 1.0\n",
      "\n",
      "\n",
      "Test 3\n",
      "Error rate: 0.48717948717948717\n",
      "Ratio of correctly classified items: 0.5128205128205128\n",
      "\n",
      "\n",
      "Test 4\n",
      "Error rate: 0.01\n",
      "Ratio of correctly classified items: 0.99\n",
      "\n",
      "\n",
      "Test 5\n",
      "Error rate: 0.98\n",
      "Ratio of correctly classified items: 0.02\n",
      "\n",
      "\n",
      "Test 6\n",
      "Error rate: 0.4891304347826087\n",
      "Ratio of correctly classified items: 0.5108695652173914\n",
      "\n",
      "\n",
      "############### BiLSTM ###################\n",
      "Test 1\n",
      "Error rate: 0.0\n",
      "Ratio of correctly classified items: 1.0\n",
      "\n",
      "\n",
      "Test 2\n",
      "Error rate: 0.0\n",
      "Ratio of correctly classified items: 1.0\n",
      "\n",
      "\n",
      "Test 3\n",
      "Error rate: 0.8717948717948718\n",
      "Ratio of correctly classified items: 0.1282051282051282\n",
      "\n",
      "\n",
      "Test 4\n",
      "Error rate: 0.04\n",
      "Ratio of correctly classified items: 0.96\n",
      "\n",
      "\n",
      "Test 5\n",
      "Error rate: 0.96\n",
      "Ratio of correctly classified items: 0.04\n",
      "\n",
      "\n",
      "Test 6\n",
      "Error rate: 0.5760869565217391\n",
      "Ratio of correctly classified items: 0.42391304347826086\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test 1: Simple sentence with one predicate\n",
    "# test 2: Simple sentence passive voice\n",
    "# test 3: instrument, location after \"by\" in passive voice\n",
    "# test 4: Different words in the same context\n",
    "# test 5: Impersonal verbs\n",
    "# test 6: Robustness\n",
    "print(\"############### BERT ###################\")\n",
    "dfs_bert = run_and_eval(dict_list, bert, save_output=True, model_name = 'BERT')\n",
    "print(\"############### BiLSTM ###################\")\n",
    "dfs_bilstm = run_and_eval(dict_list, bilstm, save_output=True, model_name = 'BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270796a-d08b-4db6-8e0e-08703f1a614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30dd3a34-0a7a-4577-a71a-c1320064939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to make table for the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db7bd956-5529-4f1b-86e0-3e62d5fea82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b514c7bf-4b8e-4a0c-b642-2e6d6a7254eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Temp\\ipykernel_13440\\3959873499.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['expected'] = df['expected'].astype(str).str.replace('[','').str.replace(']','').str.replace(',','').str.replace(\"'\", \"\")\n",
      "C:\\Users\\Hisha\\AppData\\Local\\Temp\\ipykernel_13440\\3959873499.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['expected'] = df['expected'].astype(str).str.replace('[','').str.replace(']','').str.replace(',','').str.replace(\"'\", \"\")\n"
     ]
    }
   ],
   "source": [
    "for df in dfs_bert:\n",
    "    df['expected'] = df['expected'].astype(str).str.replace('[','').str.replace(']','').str.replace(',','').str.replace(\"'\", \"\")\n",
    "\n",
    "for df in dfs_bilstm:\n",
    "    df['expected'] = df['expected'].astype(str).str.replace('[','').str.replace(']','').str.replace(',','').str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844feca-1192-49cd-a3ee-8a35c2fb0f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515c6bd-8b09-4f6b-b66c-c51fdddd570e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3e44d-2133-43ff-ab53-289271bf6593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrlll}\n",
      "\\toprule\n",
      "{} &  index &                          sentence &                                          predicted &                                         expected \\\\\n",
      "\\midrule\n",
      "0  &     14 &                  Toml oves Ruth . &                                B-V B-ARG1 I-ARG1 O &                              B-ARG0 B-V B-ARG1 O \\\\\n",
      "1  &     15 &                  Jim lvoes Mark . &                                     O B-V B-ARG2 O &                              B-ARG0 B-V B-ARG1 O \\\\\n",
      "2  &     24 &         Ashley is ilked by Mike . &                       B-ARG0 O B-V B-ARG0 I-ARG0 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "3  &     25 &      Pamela i shated by Heather . &                  B-ARG2 B-ARG0 B-V B-ARG0 I-ARG0 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "4  &     26 &           Dick is lovedb y Adam . &                  B-ARG1 B-V B-ARG2 I-ARG2 I-ARG2 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "5  &     29 &        David isl oved by Howard . &                  B-ARG0 I-ARG0 B-V B-ARG0 I-ARG0 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "6  &     30 &  Christopher is hatedb y Samuel . &                       B-ARG0 O B-V B-ARG1 I-ARG1 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "7  &     31 &         Janet is love dby Louis . &                  B-ARG1 B-V B-ARG2 I-ARG2 I-ARG2 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "8  &     32 &     Katherine is likedb y Janet . &                  B-ARG1 B-V B-ARG2 I-ARG2 I-ARG2 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "9  &     33 &         Howard is hatedb y Jeff . &                       B-ARG0 O B-V B-ARG1 I-ARG1 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "10 &     34 &          Paul is lkied by Edith . &               B-ARG0 O B-V B-ARGM-DIR I-ARGM-DIR O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "11 &     36 &           James is likde by Don . &                  B-ARG1 B-V B-ARG2 I-ARG2 I-ARG2 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "12 &     39 &        David is lvoed by Howard . &                       B-ARG0 O B-V B-ARG0 I-ARG0 O &                     B-ARG1 O B-V B-ARG0 I-ARG0 O \\\\\n",
      "13 &     40 &     He was seen by the porperty . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "14 &     41 &        He was seen yb the river . &                     O O B-V B-ARG1 I-ARG1 I-ARG1 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "15 &     42 &  He was seen by hte association . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "16 &     43 &          He was seen byt he sea . &                     O O B-V B-ARG1 I-ARG1 I-ARG1 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "17 &     44 &    He was seen by the awterfall . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "18 &     45 &        He was seen by the ifeld . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "19 &     46 &          He was seenb y the sea . &           B-ARG1 B-V B-ARG2 I-ARG2 I-ARG2 I-ARG2 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "20 &     47 &        He was seen by the canla . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "21 &     48 &  He was esen by the association . &                B-ARG0 O B-V B-ARG0 I-ARG0 I-ARG0 O &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "22 &     49 &          He aws seen by the ice . &  B-ARG0 I-ARG0 B-V B-ARGM-DIR I-ARGM-DIR I-ARGM... &  B-ARG1 O B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC O \\\\\n",
      "23 &     51 &   He was killed b ya projectile . &                     B-ARG1 O B-V O B-ARG2 I-ARG2 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "24 &     53 &      He was killed by a ifrearm . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "25 &     54 &          Hew as killed by a bow . &         O O B-V B-ARGM-MNR I-ARGM-MNR I-ARGM-MNR O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "26 &     55 &        He wsa killed by a sword . &    B-ARG1 O B-V B-ARGM-MNR I-ARGM-MNR I-ARGM-MNR O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "27 &     56 &      He wsa killed by a missile . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "28 &     57 &         eH was killed by a slug . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "29 &     58 &         He was killed by a lsug . &                B-ARG1 O B-V B-ARG0 I-ARG0 I-ARG0 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "30 &     59 &        He aws killed by a spear . &                     O O B-V B-ARG0 I-ARG0 I-ARG0 O &              B-ARG1 O B-V B-ARG2 I-ARG2 I-ARG2 O \\\\\n",
      "31 &     60 &         My fiction eats aniamls . &                         B-ARG0 I-ARG0 B-V B-ARG2 O &                       B-ARG0 I-ARG0 B-V B-ARG1 O \\\\\n",
      "32 &     63 &            My lamb eats anmials . &                         B-ARG0 I-ARG0 B-V B-ARG2 O &                       B-ARG0 I-ARG0 B-V B-ARG1 O \\\\\n",
      "33 &     66 &            My gold eats anmials . &                         B-ARG0 I-ARG0 B-V B-ARG2 O &                       B-ARG0 I-ARG0 B-V B-ARG1 O \\\\\n",
      "34 &     75 &             yM now eats animals . &                     B-ARG0 B-ARGM-TMP B-V B-ARG1 O &                       B-ARG0 I-ARG0 B-V B-ARG1 O \\\\\n",
      "35 &     81 &                   i tis snowing . &                                B-ARG0 I-ARG0 B-V O &                                        O O B-V O \\\\\n",
      "36 &     82 &                it is thundeirng . &                                B-ARG1 B-V B-ARG2 O &                                        O O B-V O \\\\\n",
      "37 &     83 &                it is htundering . &                                B-ARG1 B-V B-ARG2 O &                                        O O B-V O \\\\\n",
      "38 &     85 &                    it feels asd . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "39 &     86 &              it feels uinversal . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "40 &     87 &                 it feels simpel . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "41 &     88 &                  it feesl funny . &                            B-ARG0 B-V B-ARGM-PRD O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "42 &     89 &                   it feels ohme . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "43 &     90 &                  it feesl right . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "44 &     91 &           it feels unbelieavble . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "45 &     92 &                    ti feels bad . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "46 &     93 &              it feels peramnent . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "47 &     94 &                 it feels ofrced . &                                 O B-ARGM-ADV B-V O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "48 &     95 &                  it feesl right . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "49 &     96 &                ti feels amazing . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "50 &     97 &                   it feesl nice . &                            B-ARG0 B-V B-ARGM-PRD O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "51 &     98 &                    it feel ssad . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "52 &     99 &                   ti feels safe . &                                B-ARG0 B-V B-ARG1 O &                          B-ARG1 B-V B-ARGM-MNR O \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Temp\\ipykernel_13440\\3287721595.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(dfs_bilstm[5].to_latex())\n"
     ]
    }
   ],
   "source": [
    "# dfs_bilstm[0]\n",
    "print(dfs_bilstm[5].to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
